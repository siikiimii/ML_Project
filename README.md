# ML_Project
MLOps project with FastAPI, MLflow, and Docker
=======

# ML Project 2 â€“ MLOps with FastAPI, MLflow, and Docker

## ğŸ“Œ Overview
This project demonstrates the end-to-end lifecycle of a Machine Learning model using **MLOps practices**.

It includes:
- Data preparation, training, and evaluation
- Model tracking with **MLflow**
- Serving predictions via **FastAPI**
- Containerization with **Docker** and process management via **Supervisor**
- Automation using a **Makefile**

## âš™ï¸ Project Structure
```
â”œâ”€â”€ app.py                   # FastAPI application (prediction API)
â”œâ”€â”€ main.py                  # Entry point for data prep, training, evaluation
â”œâ”€â”€ model_pipeline.py        # ML pipeline definition
â”œâ”€â”€ model.joblib             # Trained model artifact
â”œâ”€â”€ mlflow.db                # MLflow backend store (SQLite)
â”œâ”€â”€ mlruns/                  # MLflow experiment runs
â”œâ”€â”€ Dockerfile               # Container build instructions
â”œâ”€â”€ Makefile                 # Automation commands
â”œâ”€â”€ supervisord.conf         # Supervisor config (FastAPI + MLflow)
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ test_environment.py      # Environment validation script
â””â”€â”€ venv/                    # Virtual environment (ignored in Git)
```

## ğŸš€ Setup Instructions

### 1. Local Environment
```bash
source venv/bin/activate
pip install -r requirements.txt
```

### 2. Run the ML Pipeline
```bash
python main.py prepare_data
python main.py train
python main.py evaluate
```

### 3. Start MLflow UI
```bash
mlflow ui --backend-store-uri sqlite:///mlflow.db --host 0.0.0.0 --port 5000
```
Access MLflow at: http://localhost:5000

### 4. Start FastAPI
```bash
uvicorn app:app --reload --host 0.0.0.0 --port 8000
```
Access API docs at: http://localhost:8000/docs

## ğŸ³ Docker Deployment
```bash
docker build -t mlops-project:latest .
docker run -d -p 8000:8000 -p 5000:5000   -v "$(pwd)/mlruns:/app/mlruns"   -v "$(pwd)/mlflow.db:/app/mlflow.db"   mlops-project:latest
```
FastAPI â†’ http://localhost:8000/docs  
MLflow â†’ http://localhost:5000

## ğŸ“‚ Makefile Targets
- `make install` â†’ Create virtual environment and install dependencies  
- `make prepare_data` â†’ Run data preparation  
- `make train` â†’ Train the model  
- `make test` â†’ Evaluate the model  
- `make api` â†’ Start FastAPI server  
- `make mlflow_ui` â†’ Start MLflow UI  
- `make docker-build` â†’ Build Docker image  
- `make docker-run` â†’ Run Docker container  
- `make clean` â†’ Remove generated artifacts  

## âœ… Testing
```bash
python test_environment.py
pytest -q
```

## ğŸ“¸ What to Submit
- GitHub repo link (exclude heavy artifacts via .gitignore)  
- Screenshots:
  - MLflow UI showing experiment runs and metrics
  - FastAPI docs page
  - Docker container running (`docker ps`)
- Short report (1â€“2 pages):
  - Context (dataset, model type)
  - Pipeline steps (prep â†’ train â†’ evaluate â†’ deploy)
  - Ops setup (MLflow, FastAPI, Docker, Makefile)
  - Results (metrics, artifacts)
  - Challenges & improvements

## ğŸ† Key Takeaway
This project shows how MLOps practices make ML models reproducible, trackable, and deployable in production environments.
